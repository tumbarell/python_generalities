{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhjTUEMtuvRWcj/p+1aKVS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Parallelization in Python**\n",
        "\n",
        "Example taken from\n",
        "https://towardsdatascience.com/parallelization-in-python-the-easy-way-aa03ed04c209"
      ],
      "metadata": {
        "id": "OOQQT-R6pjPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pathlib\n",
        "from typing import Dict, Generator, Iterable\n",
        "\n",
        "# type aliases\n",
        "ResultsType = Dict[str, int]\n",
        "\n",
        "def read_file(path: pathlib.Path) -> str:\n",
        "    # a file is read to a string and returned\n",
        "    # here, it's mocked by the file's name as a string\n",
        "    # this step should be rather quick\n",
        "    time.sleep(.05)\n",
        "    text = path.name\n",
        "    return text\n",
        "\n",
        "def preprocess(text: str) -> str:\n",
        "    # preprocessing is done here\n",
        "    # we make upper case of text\n",
        "    # longer than reading but quite shorter than processing\n",
        "    time.sleep(.25)\n",
        "    text = text.upper()\n",
        "    return text\n",
        "\n",
        "def process(text: str) -> ResultsType:\n",
        "    # the main process is run here\n",
        "    # we return the number of \"A\" and \"O\" letters in text\n",
        "    # this is the longest process among all\n",
        "    time.sleep(1.)\n",
        "    search = (\"A\", \"B\", )\n",
        "    results = {letter: text.count(letter) for letter in search}\n",
        "    return results\n",
        "\n",
        "def pipeline(path: pathlib.Path) -> ResultsType:\n",
        "    text = read_file(path)\n",
        "    preprocessed = preprocess(text)\n",
        "    processed = process(preprocessed)\n",
        "    return processed"
      ],
      "metadata": {
        "id": "ko8ZBT34p5DD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code above defines a pipeline to process texts:\n",
        "* read a text file\n",
        "* preprocess the file; this means cleaning and checking\n",
        "* process the file\n",
        "* return the results"
      ],
      "metadata": {
        "id": "CP1Rmy2cru-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#creating an iterable of paths\n",
        "file_paths = [\n",
        "    pathlib.Path(p)\n",
        "    for p in (\n",
        "        \"book_about_python.txt\",\n",
        "        \"book_about_java.txt\",\n",
        "        \"book_about_c.txt\",\n",
        "        \"science_fiction_book.txt\",\n",
        "        \"lolita.txt\",\n",
        "        \"go_there_and_return.txt\",\n",
        "        \"statistics_for_dummies.txt\",\n",
        "        \"data_science_part_1.txt\",\n",
        "        \"data_science_part_2.txt\",\n",
        "        \"data_science_part_3.txt\",\n",
        "    )\n",
        "]\n",
        "print('file_paths is of type: ', type(file_paths))\n",
        "list(file_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfn_qnUVsbhh",
        "outputId": "7193930d-787d-49f8-e06f-69775c7c69d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file_paths is of type:  <class 'list'>\n",
            "CPU times: user 1.78 ms, sys: 0 ns, total: 1.78 ms\n",
            "Wall time: 1.79 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('book_about_python.txt'),\n",
              " PosixPath('book_about_java.txt'),\n",
              " PosixPath('book_about_c.txt'),\n",
              " PosixPath('science_fiction_book.txt'),\n",
              " PosixPath('lolita.txt'),\n",
              " PosixPath('go_there_and_return.txt'),\n",
              " PosixPath('statistics_for_dummies.txt'),\n",
              " PosixPath('data_science_part_1.txt'),\n",
              " PosixPath('data_science_part_2.txt'),\n",
              " PosixPath('data_science_part_3.txt')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Nonparallel executions**"
      ],
      "metadata": {
        "id": "hbjQL48PtQ-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    start = time.perf_counter()\n",
        "    results = {path: pipeline(path) for path in file_paths}\n",
        "    print(f\"Elapsed time: {round(time.perf_counter() - start, 2)} seconds\")\n",
        "    print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cmrx6ciisz5h",
        "outputId": "b195d461-c7db-46df-fa45-7f1d7a1f031a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 13.01 seconds\n",
            "{PosixPath('book_about_python.txt'): {'A': 1, 'B': 2}, PosixPath('book_about_java.txt'): {'A': 3, 'B': 2}, PosixPath('book_about_c.txt'): {'A': 1, 'B': 2}, PosixPath('science_fiction_book.txt'): {'A': 0, 'B': 1}, PosixPath('lolita.txt'): {'A': 1, 'B': 0}, PosixPath('go_there_and_return.txt'): {'A': 1, 'B': 0}, PosixPath('statistics_for_dummies.txt'): {'A': 1, 'B': 0}, PosixPath('data_science_part_1.txt'): {'A': 3, 'B': 0}, PosixPath('data_science_part_2.txt'): {'A': 3, 'B': 0}, PosixPath('data_science_part_3.txt'): {'A': 3, 'B': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the same using map\n",
        "if __name__ == \"__main__\":\n",
        "    start = time.perf_counter()\n",
        "    pipeline_gen = map(lambda p: (p, pipeline(p)), file_paths)\n",
        "    # or we can use a generator expression:\n",
        "    # pipeline_gen = ((path, pipeline(path)) for path in file_paths)\n",
        "    results = dict(pipeline_gen)\n",
        "    print(f\"Elapsed time: {round(time.perf_counter() - start, 2)} seconds\")\n",
        "    print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AZ9z7wkthxm",
        "outputId": "4b458f7f-88fe-43a1-b151-cccbdd0cd42c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 13.02 seconds\n",
            "{PosixPath('book_about_python.txt'): {'A': 1, 'B': 2}, PosixPath('book_about_java.txt'): {'A': 3, 'B': 2}, PosixPath('book_about_c.txt'): {'A': 1, 'B': 2}, PosixPath('science_fiction_book.txt'): {'A': 0, 'B': 1}, PosixPath('lolita.txt'): {'A': 1, 'B': 0}, PosixPath('go_there_and_return.txt'): {'A': 1, 'B': 0}, PosixPath('statistics_for_dummies.txt'): {'A': 1, 'B': 0}, PosixPath('data_science_part_1.txt'): {'A': 3, 'B': 0}, PosixPath('data_science_part_2.txt'): {'A': 3, 'B': 0}, PosixPath('data_science_part_3.txt'): {'A': 3, 'B': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trick to simplify calls to map() that use lambda\n",
        "def evaluate_pipeline(path):\n",
        "    return path, pipeline(path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    start = time.perf_counter()\n",
        "    pipeline_gen = map(evaluate_pipeline, file_paths)\n",
        "    results = dict(pipeline_gen)\n",
        "    print(f\"Elapsed time: {round(time.perf_counter() - start, 2)}\")\n",
        "    print(results)\n",
        "\n",
        "#The map object yields a generator of two-element tuples (path, pipeline(path)).\n",
        "#We can use dict(pipeline_gen) to evaluate the generator, and\n",
        "#convert the results to a dictionary consisting of path-pipeline(path)\n",
        "#key-value pairs."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOZn8zKiup9k",
        "outputId": "fd9e9869-f08f-4c3f-ec1b-da659ea85ff4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 13.02\n",
            "{PosixPath('book_about_python.txt'): {'A': 1, 'B': 2}, PosixPath('book_about_java.txt'): {'A': 3, 'B': 2}, PosixPath('book_about_c.txt'): {'A': 1, 'B': 2}, PosixPath('science_fiction_book.txt'): {'A': 0, 'B': 1}, PosixPath('lolita.txt'): {'A': 1, 'B': 0}, PosixPath('go_there_and_return.txt'): {'A': 1, 'B': 0}, PosixPath('statistics_for_dummies.txt'): {'A': 1, 'B': 0}, PosixPath('data_science_part_1.txt'): {'A': 3, 'B': 0}, PosixPath('data_science_part_2.txt'): {'A': 3, 'B': 0}, PosixPath('data_science_part_3.txt'): {'A': 3, 'B': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Parallel execution**\n",
        "\n",
        "Let’s use multiprocessing, the standard-library module for parallelization."
      ],
      "metadata": {
        "id": "_FAaGh4QzQ9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing as mp"
      ],
      "metadata": {
        "id": "o_Hn_UM1zQHt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(f'mp cpus: {mp.cpu_count()} os cpus: {os.cpu_count()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sIl5En91GsW",
        "outputId": "97690806-4ad2-4f2f-86dc-f2c2f492a62a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mp cpus: 2 os cpus: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    start = time.perf_counter()\n",
        "    with mp.Pool(4) as p:\n",
        "        pipeline_gen = dict(p.map(evaluate_pipeline, file_paths))\n",
        "    print(f\"Elapsed time: {round(time.perf_counter() - start, 2)}\")\n",
        "    print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBQTocUYvWRM",
        "outputId": "5c1b3965-07ab-4cb1-b776-6d6bdceb5ebe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 3.96\n",
            "{PosixPath('book_about_python.txt'): {'A': 1, 'B': 2}, PosixPath('book_about_java.txt'): {'A': 3, 'B': 2}, PosixPath('book_about_c.txt'): {'A': 1, 'B': 2}, PosixPath('science_fiction_book.txt'): {'A': 0, 'B': 1}, PosixPath('lolita.txt'): {'A': 1, 'B': 0}, PosixPath('go_there_and_return.txt'): {'A': 1, 'B': 0}, PosixPath('statistics_for_dummies.txt'): {'A': 1, 'B': 0}, PosixPath('data_science_part_1.txt'): {'A': 3, 'B': 0}, PosixPath('data_science_part_2.txt'): {'A': 3, 'B': 0}, PosixPath('data_science_part_3.txt'): {'A': 3, 'B': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    start = time.perf_counter()\n",
        "    with mp.Pool(8) as p:\n",
        "        pipeline_gen = dict(p.map(evaluate_pipeline, file_paths))\n",
        "    print(f\"Elapsed time: {round(time.perf_counter() - start, 2)}\")\n",
        "    print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43d0a6a3-e140-4752-e904-14b68db61563",
        "id": "mpSVFcaMz8jV"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 2.69\n",
            "{PosixPath('book_about_python.txt'): {'A': 1, 'B': 2}, PosixPath('book_about_java.txt'): {'A': 3, 'B': 2}, PosixPath('book_about_c.txt'): {'A': 1, 'B': 2}, PosixPath('science_fiction_book.txt'): {'A': 0, 'B': 1}, PosixPath('lolita.txt'): {'A': 1, 'B': 0}, PosixPath('go_there_and_return.txt'): {'A': 1, 'B': 0}, PosixPath('statistics_for_dummies.txt'): {'A': 1, 'B': 0}, PosixPath('data_science_part_1.txt'): {'A': 3, 'B': 0}, PosixPath('data_science_part_2.txt'): {'A': 3, 'B': 0}, PosixPath('data_science_part_3.txt'): {'A': 3, 'B': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    start = time.perf_counter()\n",
        "    with mp.Pool(12) as p:\n",
        "        pipeline_gen = dict(p.map(evaluate_pipeline, file_paths))\n",
        "    print(f\"Elapsed time: {round(time.perf_counter() - start, 2)}\")\n",
        "    print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9899dd4-8cb4-4626-b9c0-be53483f03b3",
        "id": "V--dPgsu0DL6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.48\n",
            "{PosixPath('book_about_python.txt'): {'A': 1, 'B': 2}, PosixPath('book_about_java.txt'): {'A': 3, 'B': 2}, PosixPath('book_about_c.txt'): {'A': 1, 'B': 2}, PosixPath('science_fiction_book.txt'): {'A': 0, 'B': 1}, PosixPath('lolita.txt'): {'A': 1, 'B': 0}, PosixPath('go_there_and_return.txt'): {'A': 1, 'B': 0}, PosixPath('statistics_for_dummies.txt'): {'A': 1, 'B': 0}, PosixPath('data_science_part_1.txt'): {'A': 3, 'B': 0}, PosixPath('data_science_part_2.txt'): {'A': 3, 'B': 0}, PosixPath('data_science_part_3.txt'): {'A': 3, 'B': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    start = time.perf_counter()\n",
        "    with mp.Pool(10) as p:\n",
        "        pipeline_gen = dict(p.map(evaluate_pipeline, file_paths))\n",
        "    print(f\"Elapsed time: {round(time.perf_counter() - start, 2)}\")\n",
        "    print(results) #10 seems to be the maximum number of availables cores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "139ae903-2f66-43ca-d830-5c23234a5ba7",
        "id": "ZPN3l5NP0HLi"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 1.5\n",
            "{PosixPath('book_about_python.txt'): {'A': 1, 'B': 2}, PosixPath('book_about_java.txt'): {'A': 3, 'B': 2}, PosixPath('book_about_c.txt'): {'A': 1, 'B': 2}, PosixPath('science_fiction_book.txt'): {'A': 0, 'B': 1}, PosixPath('lolita.txt'): {'A': 1, 'B': 0}, PosixPath('go_there_and_return.txt'): {'A': 1, 'B': 0}, PosixPath('statistics_for_dummies.txt'): {'A': 1, 'B': 0}, PosixPath('data_science_part_1.txt'): {'A': 3, 'B': 0}, PosixPath('data_science_part_2.txt'): {'A': 3, 'B': 0}, PosixPath('data_science_part_3.txt'): {'A': 3, 'B': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* *with mp.Pool(4) as p:*: It’s a good rule to use a context manager for mp.Pool, as you do not need to remember to close the pool.\n",
        "* *p.map(evaluate_pipeline, file_paths):* The only change made was changing *map()* to *p.map()*.\n",
        "\n",
        " * *p.map()* does not evaluate lazily like *map()*, but does so greedily (immediately). Therefore, it does not return a generator; instead, it returns a list.\n",
        "\n",
        " ***Other modules for parallelization:***\n",
        " * Ray: open-source unified framework for scaling AI and Python applications (https://docs.ray.io/en/latest/index.html).\n",
        "\n",
        " * Pathos:  framework for heterogeneous computing. It provides a consistent high-level interface for configuring and launching parallel computations across heterogeneous resources (https://pathos.readthedocs.io/en/latest/index.html)."
      ],
      "metadata": {
        "id": "G7MyKp2K3xRl"
      }
    }
  ]
}